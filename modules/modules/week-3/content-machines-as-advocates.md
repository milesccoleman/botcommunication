# Content: Social Machines

## Social Machines

Usually when we're talking about something being _social_, it involves the coordination and communication between people and/or animals and/or insects and/or plants. My dog wags her tail to let me know she's happy. Blossums open to indicate that their nectar is avialable for bumble bees to consume. People smile at one another and share compliments to indicate that they appreciate others. 

Inanimate matter--like a rock--on the other hand, even if you were to talk to one, wouldn't necesarily be a social being, it is just a _thing_ that you are treating socially. As such, prevailing wisdome tells us that non-living matter can be regarded socially, but, it most emphatically is _not social_. 

But what about bots? They are made up of silicon processors firing off software. There is no way we might think of them as social beings, right? 

### 

### Social Bots

Some bots are effective because they are able to trick us into thinking that they are social beings, wielding the gravitas of a fellow person. Using the famous "Turing Test," we will define such bots below as _social bots_.  



#### The \(Social\) Turing Test 

In 1950, Alan Turing--a famous character in the history of computing and the philosophy of conciousness--came up with a test for assessing whether or not a machine had successfully reached the level of intelligence of a person.

Unsurprisingly, the Turing Test \(as it later came to be called\) relied on communication. To perform the test required that a real human being \(we'll call them Being C\) sits behind a wall with only a computer terminal connecting them to two other individuals: Being A and Being B. One of those beings is a fellow person, and the other is a computer. 

![](../../../.gitbook/assets/630px-turing_test_diagram.png)

If, after conversing with Being A and Being B, the person \(Being C\) cannot destinguish between the computer and their fellow person, one could say that the computer is sufficiently demonstrating intelligence. \(As to whether or not it _actually_ possesses intelligence is another matter, and one that Turing very wisely instructs us to avoid getting wrapped up in.\) 

While we are not necessarily interested in "spoofing" intelligence in this course, we _are_ interested in another outcome achieved by passing the Turing test: the computer's achievement of the status of a _social_ being. 

If the person cannot distinguish between the two entities behind the wall, the options they are left with are to either 1\) treat both entities as inanimate _things_, or 2\) to treat both entities as _social_ beings. Since option 1 runs the risk of treating a real person like a machine \(disrespecting that person, in other words\) we are more likely to choose option 2. 



#### The Problem of Social Machines

The problem with a machine that can pass the Turing test and successfully mimic another person is that, for better or worse, we humans appreciate when more than one person believes something. We give gravity to what our fellow social beings conclude to be true about the world. 

{% embed url="https://youtu.be/TYIh4MkcfJA" %}

If four people can encourage a person to question themselves \(even when they have a perfectly good conclusion to begin with\) then we should be alarmed to learn that on social media platforms like Twitter and Facebook it is relatively easy for a single person to command 100s or even 1000s of machines that can masquerade as social beings. 

{% hint style="success" %}
**Social bots** are bots that exact communicative effects that rely on the ability to appear as social beings. That is, social bots, are bots that employ the strategy of mimicking people in order to influence real humans. 

_Note: While not all social bot strategies rely on constructing large numbers of "followers," most social bots are employed via social media platforms._ 
{% endhint %}

Still not convinced that social bots are a reality? Go to this website and try to guess whether the excerpts are poetry made by a machine or a person. 

{% embed url="http://botpoet.com/vote/haiku12/" %}

Were you able to guess the bot communication from the human communication? Probably not 100%. 

In the case of computer generated poetry, social bots seem harmless. Conversely, social bots can be used for all sorts of malicious things. 



**Advertising Fraud**

{% embed url="https://marketingland.com/white-ops-reports-biggest-ad-fraud-botnet-found-yet-methbot-targeting-high-cpm-video-inventory-201371" %}



#### Election Tampering

{% embed url="https://www.nytimes.com/2017/09/07/us/politics/russia-facebook-twitter-election.html" %}



#### Amplifying Hate Speech

{% embed url="https://www.theguardian.com/media/2017/nov/26/anti-muslim-online-bots-fake-acounts" %}



With these kinds of examples it's easy to see that social bots are a problem. However, there are examples that at least force us to think about that easy conclusion, in that perhaps some amount of principled deception might be a good thing. 



#### Countering Racist Language

{% embed url="https://www.washingtonpost.com/news/monkey-cage/wp/2016/11/17/this-researcher-programmed-bots-to-fight-racism-on-twitter-it-worked/?noredirect=on&utm\_term=.b8c137a23ebd" %}



Because they rely on deception, here in class we won't be making social bots. But it is important to think deeply alongside the more dystopic realities of such strategies, right alongside the possibilities of more utopian ones.  

Where social bots rely on deception to be functional, there are also social machines that are more "up front" about being bots. 



### Machinic Bots

In contrast to social bots, there are also bots that are effective precisely because they are _machines._ We will defined these as _machinic bots_. 

```
$ give me super-powers
```

{% hint style="info" %}
 Super-powers are granted randomly so please submit an issue if you're not happy with yours.
{% endhint %}

Once you're strong enough, save the world:

```
// Ain't no code for that yet, sorry
echo 'You got to trust me on this, I saved the world'
```



